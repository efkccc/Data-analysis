---
title: "Chudi Thesis"
author: "Chudi Gong"
date: "17/06/2020"
output: pdf_document
bibliography: references.bib
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(tinytex)
library(vctrs)
library(dplyr)
library(magrittr)
library(ggplot2)
library(readr)
library(tidyr)
library(RColorBrewer)
library(papaja)
library(MOTE)
library(MESS)
library(lmerTest) # for mixed effects model fit
library(broom.mixed) # to tidy model fit coefficients
getwd()

# MM: This function is not needed, papaja handles this :)
myround_p <- function(x, digits = 3){
  if (x < 10^-digits) return(paste('<', 10^-digits))
  paste('=', myround(x, digits))
}

number_ticks <- function(n) {function(limits) pretty(limits, n)}
```
# 1.Abstract

# 2.Introduction 

# 3.Method 
## 3.1. Overview
The current study involved two parts: a behavioural training session lasting around 60 mins and a scanning session lasting around 90 mins with intervals no longer than two weeks. Both parts of the experiments took place at the Wellcome Centre for Human Neuroimaging, University College London. The scanning session was conducted in the 3 Tesla MRI scanner. The ethics of the current study was approved by XX. 

## 3.2. Participants
XX healthy participants were recruited, xx completed the behavioural training session and xx completed the scanning session. According to the preregistration exclusion criteria (see section 3.6. below for details), in total data from 25 participants were included in the final analysis. Participants received cash payments as compensation for their time, £10 for the behavioural session and £20 for the scanning session. To motivate participants to perform their best in our tasks, we also offered bonus payment for good performance and accurate confidence ratings (see procedure below for details on bonus calculation).  
 
## 3.3. Experimental Procedure 
### 3.3.1. Behavioural session
During behavioural training session, participants first received introductions of the study, including general procedure, ethic and data protection protocols. The structure of the three tasks (see fig.4 for the schematic representation) were explained to participants as following:

* Detection task: On half of the trials, a noisy grating will appear after the fixation cross and on the other half there would be no grating shown and you need to decide whether there was a grating present.

* Discrimination task: A grating will appear on the screen every few seconds after the fixation cross, which will be tilted clockwise in half of the trials and anticlockwise in other half. Participants were asked to decide which direction the grating was tilted to. 

* Tilt recognition task: A grating will appear on the screen every few seconds after the fixation cross, which will be tilted (to any direction) in half of the trials and vertical in other half. Participants were asked to decide whether the grating was tilted or vertical. 

* Confidence rating: In all three tasks, immediately after making a choice, you need to indicate how confident you are in your decision by changing the size of the circle.

This session contains a practice block, a calibration block and several training blocks for all three tasks. The response mapping will be counterbalanced between blocks, such that an index finger press will be used to indicate a clockwise tilt on half of the trials, and an anticlockwise tilt on the other half. Similarly, in half of the tilt recognition trials the index finger will be mapped to a vertical response, and on the other half to a tilted response. Lastly, in half of the detection trials the index finger will be mapped to a yes (‘target present’) response, and on the other half to a no (‘target absent’) response. To avoid size-related effect on confidence rating, participants were divided into two groups such that for half participants bigger circle corresponds to higher confidence level and for the other half smaller circle corresponds to higher confidence level.

During this session, each participants performance was controlled around 70 % accurate, by manipulating the task difficulty independently for the three tasks. This will be achieved by using the common 1 up 2 down staircase procedure on stimulus visibility (discrimination and detection task) and on the standard deviation of the orientation distribution (tilt recognition). Participants were not invited back to continue the scanning session if: 1.) their accuracy were lower than 60% or higher than 80%; 2.) had strong response bias, i.e. used the same response in more than 80% of the trials; 3.) had strong confidence bias, i.e. the same confidence level was reported for more than 90% of the trials. 

### 3.3.2. Scanning session
The structure of the three tasks were the same as behavioural session. To motivate participants perform we offered bonus in addition to the baseline payment for the scanning session.  Bonus is calculated use following rule:		
bonus=£$\frac{\overrightarrow{accuracy}.\overrightarrow{confidence}}{200}$. Where $\overrightarrow{accuracy}$ is a vector of 1 and -1 for correct and incorrect responses, and $\overrightarrow{confidence}$ is a vector of integers in the range of 1 to 6, representing confidence reports for all trials. The rule for bonus calculation was explained to participants in both sessions. The scanning session started with a calibration phase to further calibrate participants performance during which time the structural scan for each participant was also obtained. At scanning, 10 discrimination and detection blocks were presented in 5 scanner runs. 

## 3.4. Overview
After a temporal rest period of 500-4000 milliseconds, each trial will start with a fixation cross (500 milliseconds). The target was then presented on the screen for 500 milliseconds. In all three conditions, stimuli will consist of 10 grayscale frames presented at 20 frames per second within a circle of diameter 3°. Stimuli will be generated in the following way:

* Generate 10 grayscale frames ( _F_ ... _F_ ), each an array of 142 by 142 random luminance values.
* Create a 142 by 142 sinusudial grating ( 24 pixels per period, random phase). The orientation of the grating is determined according to the trial type.
* The grating visibility for frame _i_ is _pi_ = _v_ × _exp_(-$|\textit{i}-5|$/2) with _v_ being the visibility level in this trial (0 for target-absent trials).
* For each pixel in the frame , replace the luminance value for this pixel with the luminance value of this pixel in the grating with a probability of.

## 3.5. Scanning parameters 
Scanning took place at the Wellcome Centre for Human Neuroimaging, London. The structural images were obtained using an MPRAGE sequence (1x1x1 _mm_ voxels, 176 slices, in plane FoV = 256x256 _mm_ 2), followed by a double-echo FLASH (gradient echo) sequence with TE1=10ms and TE2=12.46ms (64 slices, slice thickness = 2 _mm_, gap = 1 _mm_, in plane FoV= 192×192 _mm_ 2, resolution = 3×3 _mm_ 2) that were later used for field inhomogeneity correction. Functional scans were acquired using a 2D EPI sequence, optimized for regions near the orbitofrontal cortex (3.0x3.0x3.0 _mm_ voxels, TR=3.36 seconds, TE = 30 ms, 48 slices tilted by -30 degrees with respect to the T¿C axis, matrix size = 64x72, Z-shim=-1.4).

```{r include=FALSE, cache=TRUE}

#open file
Data <- read.csv("Data.csv")

#creat a new file with only includedtrials 
Data_Valid <- Data %>% 
  #Filter out the excluded trials 
  filter(inclusion==1) %>%
  filter(! response=="NaN") %>%
  mutate(rt=response_time*1000) %>%
  mutate(log_rt=log(rt))

# MM: since you're not using Behavioural subj anywhere I figured 
# this was a more economical way to get the number of subjects:
no_subj <- length(unique(Data_Valid$subj_id))

Data_Det <- Data_Valid %>% 
  #only include detection 
  filter(task=="Detection")

Data_Dis <- Data_Valid %>% 
  #only include discrimination
  filter(task=="Discrimination")

Data_Til<- Data_Valid %>% 
  #only include tilt recognition 
  filter(task=="Tilt")

#count the total no of trials for each task for each participant
total_trials <- Data_Valid %>%
  group_by(subj_id, task) %>%
  summarise(totaltrials=(count=n()))

#get the number of trials for each participants where the stimulus shown is 1 (i.e.Present, Clockwise & Tilted)
sti_trials <- Data_Valid %>%
  group_by(subj_id, task) %>%
  filter(stimulus=="1") %>%
  summarise(sti_trials=(count=n()))
sti_trials

#count no. of correct trials for each task for each participant
individual_trials <- Data_Valid %>% 
  #group by ID, type of task and accuracy
  group_by(subj_id, task, accuracy) %>% 
  #count number of correct/incorrect/NAH trials 
  summarize(no_trials=(count = n())) %>%
  #combine with the total data frame
  inner_join(total_trials, by = c ("subj_id","task")) %>%
  mutate(proportion = no_trials / totaltrials)
individual_trials

#display accuracy 
individual_accuracy <- individual_trials %>%
  filter(accuracy==1) %>%
  rename(correct=proportion)
individual_accuracy
```

# 4.Results
## 4.1.Performance across threee tasks
```{r, include=FALSE, cache=TRUE}
#display accuracy for each task 
task_accuracy <- individual_accuracy %>%
  group_by(task) %>%
  summarise(mean(correct)) %>%
  spread(key='task', value='mean(correct)')
task_accuracy

#ANOVA comparing task performance 
aov.Mean_accuracy <- aov(correct~task,data=individual_accuracy)

## MM: you can then use apa_print(aov.Mean_accuracy) to present stats.

#############################
#calculating HIT and FA rate
#############################

#combine with the ptrials data frame
trials <- Data_Valid %>% 
  #group by ID, type of task and accuracy
  group_by(subj_id, task, accuracy, response) %>% 
  #count number of correct/incorrect/NAH trials 
  summarize(no_trials=(count = n())) %>%
  inner_join(sti_trials, by = c ("subj_id","task"))
trials

# MM: no need to assert variable names after defining them
# trials

#calculating HIT FA rate for detection
hit_det <- trials %>% 
  filter(task=="Detection", response== "1", accuracy=="1") %>%
  mutate(hit_rate = no_trials / sti_trials) %>%
  mutate(z_hit= qnorm(hit_rate))
hit_det

#calculating mean HIT rate for detection
mean_mean_det_hit <- mean(hit_det$hit_rate)

fa_det <- trials %>% 
  filter(task=="Detection", response== "1", accuracy=="0") %>%
  mutate(fa_rate = no_trials / sti_trials) %>%
  mutate(z_fa= qnorm(fa_rate)) %>%
  inner_join(hit_det, by = c ("subj_id","task", "response", "sti_trials")) %>%
  mutate(dprime= z_hit-z_fa)
fa_det

#calculating mean FA rate for detection
det_fa <- mean(fa_det$fa_rate)

#calculating HIT FA for discrimination
hit_dis <- trials %>% 
  filter(task=="Discrimination", response== "1", accuracy=="1") %>%
  mutate(hit_rate = no_trials / sti_trials) %>%
  mutate(z_hit= qnorm(hit_rate))
hit_dis

fa_dis<- trials %>% 
  filter(task=="Discrimination", response== "1", accuracy=="0") %>%
  mutate(fa_rate = no_trials / sti_trials)%>%
  mutate(z_fa= qnorm(fa_rate)) %>%
  inner_join(hit_dis, by = c ("subj_id","task", "response", "sti_trials")) %>%
  mutate(dprime= z_hit-z_fa)
fa_dis

#calculating HIT FA rate for tilt
hit_til <- trials %>% 
  filter(task=="Tilt", response== "1", accuracy=="1") %>%
  mutate(hit_rate = no_trials / sti_trials) %>%
  mutate(z_hit= qnorm(hit_rate))
hit_til

til_hit <- mean(hit_til$hit_rate)

fa_til<- trials %>% 
  filter(task=="Tilt", response== "1", accuracy=="0") %>%
  mutate(fa_rate = no_trials / sti_trials) %>%
  mutate(z_fa= qnorm(fa_rate)) %>%
  inner_join(hit_til, by = c ("subj_id","task", "response", "sti_trials")) %>%
  mutate(dprime= z_hit-z_fa) 
fa_til
til_fa <- mean(fa_til$fa_rate)

#merge together 
d_prime <- rbind(fa_det, fa_dis, fa_til)

#d values for each task
d_det <- mean(fa_det$dprime)
d_dis <- mean(fa_dis$dprime)
d_til <- mean(fa_til$dprime)

# MM: I want to encourage you to use functions more where you write the same
# script over and over again. Having code duplicates in your code is reallllly
# error-prone. So whenever you find yourself having to write the same thing 
# more than once (e.g. you extract d' for each task in a very similar way), 
# write a function instead. I would encourage you to write a function 'get_d'
# that takes a df as input and returns the d' for this table, and then groupby task 
# and subject and use summarise with your new function.


#ANOVA Calculation for d prime
aov.d <- aov(dprime~task, data=d_prime)

# MM: here also, no need to extract ps and fs, you can use apa_print() instead :)
summary(aov.d)
p2 <- summary(aov.d)[[1]][["Pr(>F)"]][[1]]
F2<- summary(aov.d)[[1]][["F value"]][[1]]

###########################
#response bias calculation
###########################
response <- Data_Valid %>% 
  #group by ID, type of task and accuracy
  group_by(subj_id,task, response) %>% 
  #count number of correct/incorrect/NAH trials 
  summarize(no_trials=(count = n())) %>%
  #combine with the total data frame
  inner_join(total_trials, by = c ("task","subj_id")) %>%
  mutate(probability = no_trials / totaltrials)
response

#response bias for detection
det_resp <- response %>%
  filter(task=="Detection") %>%
  filter(response=="1")
det_resp

# MM: Here's a really cool thing: instead of extracting mean and sd, 
# you can use apa_print(t.test(...))$estimate instead!

det_bias <- mean(det_resp$probability)
sd_bias1 <- sd(det_resp$probability)

# MM: what is this variable?
detection<- (rnorm(no_subj, mean = det_bias, sd = sd_bias1))
# MM: aren't you saving the t.test results to a variable?
t.test(detection, mu = 0.5) # Ho: mu = 0.5

# MM: same principle here. if you are writing the same code three times,
# it's better to write a function instead :)

#response bias for discrimination
dis_resp <- response %>%
  filter(task=="Discrimination") %>%
  filter(response=="1")
dis_resp

dis_bias <- mean(dis_resp$probability)
sd_bias2 <- sd(dis_resp$probability)
discrimination<- (rnorm(no_subj, mean = dis_bias, sd = sd_bias2))
t.test(discrimination, mu = 0.5) # Ho: mu = 0.5

#response bias for tilt recognition
til_resp <- response %>%
  filter(task=="Tilt") %>%
  filter(response=="1")
til_resp

til_bias <- mean(til_resp$probability)
sd_bias3 <- sd(til_resp$probability)
tilt<- (rnorm(no_subj, mean = til_bias, sd = sd_bias3))
t.test(tilt, mu = 0.5) # Ho: mu = 0.5

#####################
#calculating rt
#####################
rt <- Data_Valid %>%
  group_by(subj_id, task, response, accuracy) %>%
  summarise(median(rt)) %>%
  rename("median_rt"="median(rt)")
rt

#calculating median rt for correct and incorrect trials
rt_accuracy <- rt %>%
  group_by(accuracy) %>%
  summarise(median(median_rt)) %>%
  rename("median_rt"="median(median_rt)") 
rt_accuracy

rt_accuracy$accuracy[rt_accuracy$accuracy=="0"]<-"incorrect"
rt_accuracy$accuracy[rt_accuracy$accuracy=="1"]<-"correct"

#calling out median rt for correct and incorrect trials
getmedian <- rt_accuracy$'median_rt'
names(getmedian) <-rt_accuracy$accuracy

#calling out quantiles of rt for correct and incorrect trials
correct_trials <- rt %>%
  filter(accuracy==1)
correct_trials

incorrect_trials <- rt %>%
  filter(accuracy==0)
incorrect_trials 

# MM: why not use qt_correct <- quantile(correct_trials$median_rt, c(.25,.5,.75)) instead?
qt1_correct <- quantile(correct_trials$median_rt, c(.25)) 
qt3_correct <- quantile(correct_trials$median_rt, c(.75))
qt1_incorrect <- quantile(incorrect_trials$median_rt, c(.25)) 
qt3_incorrect <- quantile(incorrect_trials$median_rt, c(.75))

#get t test results detection, discrimination and tilt 
# MM: I would use papaja instead here.
tdet <-t.test(log_rt~response, mu=0, alt="two.sided", conf=0.95,var.equal=TRUE, data=Data_Det)$statistic
p.det <- t.test(log_rt~response, mu=0, alt="two.sided",conf=0.95,var.equal=TRUE, data=Data_Det)$p.value

tdis <-t.test(log_rt~response, mu=0, alt="two.sided", conf=0.95,var.equal=TRUE,data=Data_Dis)$statistic
p.dis <-t.test(log_rt~response, mu=0, alt="two.sided", conf=0.95,var.equal=TRUE,data=Data_Dis)$p.value

ttil <-t.test(log_rt~response, mu=0, alt="two.sided", conf=0.95,var.equal=TRUE,data=Data_Til)$statistic
p.til <-t.test(log_rt~response, mu=0, alt="two.sided",conf=0.95,var.equal=TRUE,data=Data_Til)$p.value

```

Detection (accuracy= `r printnum(task_accuracy$Detection)`, d'= `r apa(d_det, 2, T)`),  discrimination (accuracy= `r printnum(task_accuracy$Discrimination)`, d'= `r apa(d_dis, 2, T)`) and tilt recognition (accuracy = `r printnum(task_accuracy$Tilt)`, d'= `r apa(d_til, 2, T)`) was similar. A one-way ANOVA failed to detect a significant difference between the accuracy of these three tasks `r apa_print(aov.Mean_accuracy)$full_result$task` and d' (F= `r apa(F2, 2, T)`, p= `r apa(p2, 2, T)`; see Figure \ref{fig:accuracy})).

The probability of responding YES in detection was `r format(round(print(det_bias), 2), nsmall = 2)` (± `r apa(sd_bias1, 2, T)`), and was significantly different from 0.5 (ADD T TEST RESULTS). The probability of responding CLOCKWISE was `r apa(dis_bias, 2, T)` (± `r apa(sd_bias2, 2, T)`) and was not significantly different from 0.5. For the tilt recognition task, the probability of responding TILTED was (`r apa(til_bias, 2, T)` ± `r apa(sd_bias3, 2, T)`).

Response time was faster for correct response (1st quartile= `r apa(qt1_correct, 2, T)`, median= `r apa(unname(getmedian['correct']), 2, T)`, 3rd quartile= `r apa(qt3_correct, 2, T)` milliseconds) than incorrect responses (1st quartile= `r apa(qt1_incorrect, 2, T)`, median= `r apa(unname(getmedian['incorrect']), 2, T)`, 3rd quartile= `r apa(qt3_incorrect, 2, T)` milliseconds). A one-way analysis of variance failed to detect a significant overall effect of responses type in detection (YES vs. NO, t=`r apa(tdet, 2, T)` p=`r apa(p.det, 2, T)` ), discrimination (CLOCKWISE vs. ANTICLOCKWISE, t=`r apa(tdis, 2, T)`, p= `r apa(p.dis, 2, T)`) and tilt recognition (VERTICAL vs. TILTED, t=`r apa(ttil, 2, T)`, p= `r apa(p.til, 2, T)`) on response time.

```{r, accuracy_figure, echo=FALSE, message=FALSE,fig.cap="\\label{fig:accuracy} Mean accuracy across three tasks", cache=TRUE}
## MM: note how I've included fig.cap in the header, to include a caption and also a label (fig:accuracy) that we can later reference in the text.
number_ticks <- function(n) {function(limits) pretty(limits, n)}
data <- individual_accuracy
ggplot(data, mapping = aes(x= task, y=correct)) + ylim(0.4, 1) +labs (y="mean accuracy")+ theme_classic() +
   geom_boxplot()+ geom_jitter(position=position_jitter(width=.1, height=0), alpha=0.3, size=4) + scale_y_continuous(breaks=number_ticks(6), limits=c(0.4, 1)) + geom_hline(yintercept=0.5, linetype="dashed", color = "black") + theme(plot.title = (element_text(color = "black", size = 12, face = "italic")))
```

```{r include=FALSE, cache=TRUE}
#mean confidence frequency 
# MM: instead of creating three different dfs, I kept everything in one df here:
confidence_distribution <- Data_Valid %>%
  group_by(task,confidence,response) %>%
  summarise(no_trials=(count=n())) %>%
  mutate(frequency = no_trials / no_subj)
confidence_distribution

confidence_distribution$response[(confidence_distribution$response=="0") &
                                   confidence_distribution$task=='Detection'] <- "No"

confidence_distribution$response[(confidence_distribution$response=="1") &
                                   confidence_distribution$task=='Detection'] <- "Yes"

confidence_distribution$response[(confidence_distribution$response=="0") &
                                   confidence_distribution$task=='Discrimination'] <- "Anticlockwise"

confidence_distribution$response[(confidence_distribution$response=="1") &
                                   confidence_distribution$task=='Discrimination'] <- "Clockwise"

confidence_distribution$response[(confidence_distribution$response=="0") &
                                   confidence_distribution$task=='Tilt'] <- "Vertical"

confidence_distribution$response[(confidence_distribution$response=="1") &
                                   confidence_distribution$task=='Tilt'] <- "Tilted"

confidence_distribution$response <- factor(confidence_distribution$response, levels=c('No','Yes','Anticlockwise','Clockwise','Vertical','Tilted'))

det <- Data_Valid %>%
  filter(task=="Detection") 
det

dis <- Data_Valid %>%
  filter(task=="Discrimination") 
dis

til <- Data_Valid %>%
  filter(task=="Tilt") 
til

p1 <- t.test(confidence~response, mu=0, alt="two.sided", conf=0.95, data = det)$p.value
t1 <- t.test(confidence~response, mu=0, alt="two.sided", conf=0.95, data = det)$statistic
p3 <- t.test(confidence~response, mu=0, alt="two.sided", conf=0.95, data = til)$p.value
t3 <- t.test(confidence~response, mu=0, alt="two.sided", conf=0.95, data = til)$statistic
```
&nbsp;

## 4.2.Confidence distributions
Within detection, a significant difference in mean confidence was observed between YES (target present) and NO (target absent) responses (see Fig.4 above) (t=`r apa(t1, 2, T)`, p = `r myround_p (apa(p1, 2, T))`) , such that participants are more confident in their YES responses than NO response and a statistical significance was also observed in the tilt recognition task between TILTED and Vertical response (t=`r apa(t3, 2, T)`, p = `r myround_p(apa(p3, 2, T))`; see Figure \ref{fig:confidence}).

```{r echo=FALSE, message=FALSE, fig.cap="\\label{fig:confidence} Confidence distributions across three tasks and responses. Error bars represent the standard error of the mean.", cache=TRUE}

#plot the frequency of confidence ratings for all three tasks
task_labs = c('Detection','Discrimination','Tilt Recognition')
names(task_labs) = c('Detection','Discrimination','Tilt')
cbPalette <- c("#e41a1c", "#377eb8","#4daf4a", "#984ea3","#999999","#f781bf")
confidence_det <- ggplot(confidence_distribution, mapping = aes(x = confidence, y= frequency, fill= response)) +
  geom_bar(stat="identity", width = 0.65, position = position_dodge(width = 0.7))+ scale_fill_manual(values=cbPalette) + theme_classic() + labs(title="Confidence by task and response", y="frequency")+ scale_x_continuous(breaks=number_ticks(6)) + geom_errorbar(aes(ymin=frequency-ci, ymax=frequency+ci), width=.1, position=pd) +ylim(0,30)+
  theme(plot.title = (element_text(color = "black", size = 12, face = "italic")))
confidence_det+facet_grid(rows=vars(task),
                          labeller = labeller(task=task_labs))
```

&nbsp;

&nbsp;

```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=3, fig.height=3, cache=TRUE}
#Type 2 ROC preparation
sti <- Data_Valid %>%
  group_by(subj_id, task, stimulus) %>%
  summarise(total_sti_trials=(count=n())) 
sti

#get the total number of trials for correct and incoccrect trials
acc <- Data_Valid %>%
  group_by(subj_id, task, accuracy, response) %>%
  summarise(total_acc_trials=(count=n())) 
acc

conf_prob_acc <- Data_Valid %>%
  group_by(subj_id, task, stimulus, response, accuracy, confidence) %>%
  summarise(no_trials=(count=n())) %>%
  inner_join(acc, by = c ("subj_id","task", "response","accuracy")) %>%
  mutate(prob_acc= no_trials/total_acc_trials)
conf_prob_acc

conf_prob <- Data_Valid %>%
  group_by(subj_id, task, stimulus, response, accuracy, confidence) %>%
  summarise(no_trials=(count=n())) %>%
  inner_join(sti, by = c ("subj_id","task", "stimulus")) %>%
  mutate(prob= no_trials/total_sti_trials) %>%
  inner_join(conf_prob_acc, by = c ("subj_id","task", "stimulus", "response", "confidence","accuracy", "no_trials"))
conf_prob

###############
#  Detection  #
###############
#Detection peparation
#include only trials for detection
conf_det <- conf_prob %>%
  filter(task=="Detection")
conf_det

#get incorrect trials 
conf_det0 <- subset(conf_det, accuracy=="0", select=c(confidence, response, prob_acc))
conf_det0 <- conf_det0[order(conf_det0[,1,2]),]
sex1 <- se(conf_det0$prob_acc)


# MM: in the following lines, why use many dfs instead of piping the commands?
#get incorrect trials with 1 response
confdet_incorrect1 <- conf_det0 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="1")
confdet_incorrect1

#get incorrect trials with 0 response
confdet_incorrect0 <- conf_det0 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="0")
confdet_incorrect0

#order df with descending confidence
confdet_incorrect0 <- confdet_incorrect0[order(-confdet_incorrect0$confidence),]
confdet_incorrect1 <- confdet_incorrect1[order(-confdet_incorrect1$confidence),]

#get cumulative prob
confdet_incorrect0[,'prob0']=cumsum(confdet_incorrect0[,'prob'])
confdet_incorrect1[,'prob0']=cumsum(confdet_incorrect1[,'prob'])

#bind incorrect trials together
confdet_incorrect <- rbind(confdet_incorrect0, confdet_incorrect1)

#get correct trials
conf_det1 <- subset(conf_det, accuracy=="1", select=c(confidence, response, prob_acc))
conf_det1 <- conf_det1[order(conf_det1[,1,2]),]
sey1 <- se(conf_det1$prob_acc)

#get correct trials with 1 response
confdet_correct1 <- conf_det1 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="1")
confdet_correct1 

#get correct trials with 0 response
confdet_correct0 <- conf_det1 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="0")
confdet_correct0

#order df with descending confidence
confdet_correct0 <- confdet_correct0[order(-confdet_correct0$confidence),]
confdet_correct1 <- confdet_correct1[order(-confdet_correct1$confidence),]

#get cumulative prob
confdet_correct0[,'prob1']=cumsum(confdet_correct0[,'prob'])
confdet_correct1[,'prob1']=cumsum(confdet_correct1[,'prob'])

#bind correct trials together
confdet_correct <- rbind(confdet_correct0, confdet_correct1)

#bind incorrect and correct trials together
confdet_acc <- inner_join(confdet_incorrect, confdet_correct, by=c("confidence", "response"))

#add the row for zero point for the ROC plot
confdet_acc <- ungroup(confdet_acc)

confdet_acc <- confdet_acc %>% add_row(confidence=7, response=0, prob_acc.x=0, prob.x=0, prob0=0, prob_acc.y=0, prob.y=0, prob1=0) %>% add_row(confidence=7, response=1, prob_acc.x=0, prob.x=0, prob0=0, prob_acc.y=0, prob.y=0, prob1=0)

#change response code
confdet_acc$response[confdet_acc$response=="0"] <- "No"
confdet_acc$response[confdet_acc$response=="1"] <- "Yes"

#calculating area under the curve
auc_detection <- t(sapply(split(confdet_acc, confdet_acc$response), function(x) {
  data.frame(response=x$response[1], auc=auc(x$prob0, x$prob1, type='spline'))
}))
AUC_det <- merge(confdet_acc, auc_detection)
AUC_det$auc <- as.numeric(AUC_det$auc)
auc_det <- AUC_det$'auc'
names(auc_det) <-AUC_det$response

#t test comparing area under the curve 
#det_auc<- (rnorm(no_subj, mean = unname(auc_det['No']), sd = sd_bias2))
#t.test(det_auc, mu = unname(auc_det['Yes'])) # 

#det_auc <- (rnorm(no_subj, mean = dis_bias, sd = sd_bias2))
#t.test(det_auc, mu = unname) # Ho: mu = 0.5

####################
#  Discrimination  #
####################
conf_dis <- conf_prob %>%
  filter(task=="Discrimination")
conf_dis

#get incorrect trials 
conf_dis0 <- subset(conf_dis, accuracy=="0", select=c(confidence, response, prob_acc))
conf_dis0 <- conf_dis0[order(conf_dis0[,1,2]),]

confdis_incorrect1 <- conf_dis0 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="1")
confdis_incorrect1

confdis_incorrect0 <- conf_dis0 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="0")
confdis_incorrect0

confdis_incorrect0 <- confdis_incorrect0[order(-confdis_incorrect0$confidence),]
confdis_incorrect1 <- confdis_incorrect1[order(-confdis_incorrect1$confidence),]

confdis_incorrect0[,'prob0']=cumsum(confdis_incorrect0[,'prob'])
confdis_incorrect1[,'prob0']=cumsum(confdis_incorrect1[,'prob'])

confdis_incorrect <- rbind(confdis_incorrect0, confdis_incorrect1)

conf_dis1 <- subset(conf_dis, accuracy=="1", select=c(confidence, response, prob_acc))
conf_dis1 <- conf_dis1[order(conf_dis1[,1,2]),]

confdis_correct1 <- conf_dis1 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="1")
confdis_correct1

confdis_correct0 <- conf_dis1 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="0")
confdis_correct0

confdis_correct0 <- confdis_correct0[order(-confdis_correct0$confidence),]
confdis_correct1 <- confdis_correct1[order(-confdis_correct1$confidence),]

confdis_correct0[,'prob1']=cumsum(confdis_correct0[,'prob'])
confdis_correct1[,'prob1']=cumsum(confdis_correct1[,'prob'])

confdis_correct <- rbind(confdis_correct0, confdis_correct1)
confdis_acc <- inner_join(confdis_incorrect, confdis_correct, by=c("confidence", "response"))
confdis_acc <- ungroup(confdis_acc)
confdis_acc <- confdis_acc %>% add_row(confidence=7, response=0, prob_acc.x=0, prob.x=0, prob0=0, prob_acc.y=0, prob.y=0, prob1=0) %>% add_row(confidence=7, response=1, prob_acc.x=0, prob.x=0, prob0=0, prob_acc.y=0, prob.y=0, prob1=0)
confdis_acc$response[confdis_acc$response=="0"] <- "Anticlockwise"
confdis_acc$response[confdis_acc$response=="1"] <- "Clockwise"

#Tilt recognition
conf_til <- conf_prob %>%
  filter(task=="Tilt")
conf_til

conf_til0 <- subset(conf_til, accuracy=="0", select=c(confidence, response, prob_acc))
conf_til0 <- conf_til0[order(conf_til0[,1,2]),]

conftil_incorrect1 <- conf_til0 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="1")
conftil_incorrect1

conftil_incorrect0 <- conf_til0 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="0")
conftil_incorrect0

conftil_incorrect0 <- conftil_incorrect0[order(-conftil_incorrect0$confidence),]
conftil_incorrect1 <- conftil_incorrect1[order(-conftil_incorrect1$confidence),]

conftil_incorrect0[,'prob0']=cumsum(conftil_incorrect0[,'prob'])
conftil_incorrect1[,'prob0']=cumsum(conftil_incorrect1[,'prob'])

conftil_incorrect <- rbind(conftil_incorrect0, conftil_incorrect1)

conf_til1 <- subset(conf_til, accuracy=="1", select=c(confidence, response, prob_acc))
conf_til1 <- conf_til1[order(conf_til1[,1,2]),]

conftil_correct1 <- conf_til1 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="1")
conftil_correct1

conftil_correct0 <- conf_til1 %>%
  group_by(confidence, response) %>%
  summarise_each(funs(sum)) %>%
  mutate(prob= prob_acc/no_subj) %>%
  filter(response=="0")
conftil_correct0

conftil_correct0 <- conftil_correct0[order(-conftil_correct0$confidence),]
conftil_correct1 <- conftil_correct1[order(-conftil_correct1$confidence),]

conftil_correct0[,'prob1']=cumsum(conftil_correct0[,'prob'])
conftil_correct1[,'prob1']=cumsum(conftil_correct1[,'prob'])
conftil_correct <- rbind(conftil_correct0, conftil_correct1)
conftil_acc <- inner_join(conftil_incorrect, conftil_correct, by=c("confidence", "response"))
conftil_acc <- ungroup(conftil_acc)
conftil_acc <- conftil_acc %>% add_row(confidence=7, response=0 ,prob_acc.x=0, prob.x=0, prob0=0, prob_acc.y=0, prob.y=0, prob1=0) %>% add_row(confidence=7, response=1 ,prob_acc.x=0, prob.x=0, prob0=0, prob_acc.y=0, prob.y=0, prob1=0)

conftil_acc$response[conftil_acc$response=="0"] <- "Vertical"
conftil_acc$response[conftil_acc$response=="1"] <- "Tilted"

#calculating area under the curve
auc_tilt <- t(sapply(split(conftil_acc, conftil_acc$response), function(x) {
  data.frame(response=x$response[1], auc=auc(x$prob0, x$prob1, type='spline'))
}))
AUC_til <- merge(conftil_acc, auc_tilt)
AUC_til$auc <- as.numeric(AUC_til$auc)
auc_til <- AUC_til$'auc'
names(auc_til) <-AUC_til$response
```

## 4.4.Metacognitive sensitivity
Metacognitive sensitivity, which is quantified as the area under Type 2 ROC curve (see \ref{fig:type2 ROC}), is significantly higher for Yes (`r apa(unname(auc_det['Yes']), 2, T) `) than No (`r apa(unname(auc_det['No']), 2, T)`) response. Similar pattern is observed in the tilt recognition task, where the AUC is significantly higher for Tilted (`r apa(unname(auc_til['Tilted']), 2, T)`) than Vertical (`r apa(unname(auc_til['Vertical']), 2, T)`) responses. This suggest that participants confidence ratings are more diagnostic to accuracy in the judgments of a target stimulus being pressent than being absent. Similarly, the correct judgments of a stimulus being tilted is better reflected by partcipants' confidence ratings than the correct judgments of a stimulus being vertical. 

```{r echo=FALSE, message=FALSE, fig.cap="\\label{fig:type2 ROC} Type 2 ROC curve for each task", cache=TRUE}
#################################### 
# Plotting type 2 ROC
####################################
roc2_det <- ggplot(data=confdet_acc, aes(x=prob0, y=prob1)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 4) + 
  scale_color_manual(values=c("#e41a1c", "#377eb8")) +
  labs(title="Fig.8 Type 2 ROC Detection", x= "p(conf | correct)", y="p(conf | incorrect)", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0, 1),breaks=number_ticks(6)) + scale_y_continuous(limits = c(0, 1), breaks=number_ticks(6)) +
  theme(legend.position=c(0.8, 0.2),  
                 legend.background = element_blank(),
        legend.title = element_blank(),
                 legend.key = element_blank(), 
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
roc2_det


roc2_dis <- ggplot(data=confdis_acc, aes(x=prob0, y=prob1)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 4) + 
  scale_color_manual(values=c("#984ea3", "#4daf4a")) +
  labs(title="Fig.9 Type 2 ROC Discrimination", x= "p(conf | correct)", y="p(conf | incorrect)", color="Response")+ 
  theme_classic() + scale_x_continuous(limits = c(0, 1),breaks=number_ticks(6)) + scale_y_continuous(limits = c(0, 1), breaks=number_ticks(6)) +
  theme(legend.position=c(0.8, 0.2),  
                 legend.background = element_blank(),
        legend.title = element_blank(),
                 legend.key = element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic")))
roc2_dis

roc2_til <- ggplot(data=conftil_acc, aes(x=prob0, y=prob1)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 4) + 
  scale_color_manual(values=c("#999999","#f781bf")) +
  labs(title="Fig.10 Type 2 ROC Tilt", x= "p(conf | correct)", y="p(conf | incorrect)", color="Response")+ 
  theme_classic()+ scale_x_continuous(limits = c(0, 1),breaks=number_ticks(6)) + scale_y_continuous(limits = c(0, 1), breaks=number_ticks(6)) +
  theme(legend.position=c(0.8, 0.2),  
                 legend.title = element_blank(),
        legend.background = element_blank(),
                 legend.key = element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic")))
roc2_til
```

&nbsp;

&nbsp;

## 4.5.BOLD signal in ROIs
```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3.2, cache=TRUE}
####################################
# BOLD data preparation detection 
####################################
Data_Det <- Data_Det %>%
  filter(! BOLD_rTPJ=="NaN")
Data_Det
Data_Det$response[Data_Det$response=="0"] <- "No"
Data_Det$response[Data_Det$response=="1"] <- "Yes"

#get the mean activation at each ROI for each participants at each confidence level for each response
BOLD_det_subj <- aggregate(Data_Det[, 16:21], list(Data_Det$subj_id, Data_Det$confidence, Data_Det$response, Data_Det$task ), mean)

#MM: what is the meaning of these column names (Group.1 etc?)
BOLD_det_subj <- rename(BOLD_det_subj,c('subj_id'='Group.1', 'confidence'='Group.2', 'response'='Group.3', 'task'='Group.4'))

#get the group mean of activation for each ROI
BOLD_det_mean <- aggregate(BOLD_det_subj[, 5:10], list(BOLD_det_subj$confidence, BOLD_det_subj$response), mean)
#get the se of activation for each ROI
BOLD_det_se <- aggregate(BOLD_det_subj[, 5:10], list(BOLD_det_subj$confidence, BOLD_det_subj$response ), se)
#combine with mean df==> ".x==mean, .y==se"

#MM: It's generally not a good idea to use the same variable name twice for different things (see line 1060)
BOLD_det_mean <- inner_join(BOLD_det_mean, BOLD_det_se, by=c("Group.1", "Group.2"))
#rename the colum names 
BOLD_det_mean <- rename(BOLD_det_mean,c('confidence'='Group.1', 'response'='Group.2'))

######################################### 
# BOLD data preparation discrimination 
#########################################

# MM: same here, using a function is better :)
Data_Dis <- Data_Dis %>%
  filter(! BOLD_rTPJ=="NaN")
Data_Dis
Data_Dis$response[Data_Dis$response=="0"] <- "Anticlockwise"
Data_Dis$response[Data_Dis$response=="1"] <- "Clockwise"

#get the mean activation at each ROI for each participants at each confidence level for each response
BOLD_dis_subj <- aggregate(Data_Dis[, 16:21], list(Data_Dis$subj_id, Data_Dis$confidence, Data_Dis$response, Data_Dis$task), mean)
#rename the colum names 
BOLD_dis_subj <- rename(BOLD_dis_subj,c('subj_id'='Group.1', 'confidence'='Group.2', 'response'='Group.3', 'task'='Group.4'))
#get the group mean of activation for each ROI
BOLD_dis_mean <- aggregate(BOLD_dis_subj[, 5:10], list(BOLD_dis_subj$confidence, BOLD_dis_subj$response ), mean)
#get the se of activation for each ROI
BOLD_dis_se <- aggregate(BOLD_dis_subj[, 5:10], list(BOLD_dis_subj$confidence, BOLD_dis_subj$response ), se)
#combine with mean df==> ".x==mean, .y==se"
BOLD_dis_mean <- inner_join(BOLD_dis_mean, BOLD_dis_se, by=c("Group.1", "Group.2"))
#rename the colum names 
BOLD_dis_mean <- rename(BOLD_dis_mean,c('confidence'='Group.1', 'response'='Group.2'))

#################################### 
# BOLD data preparation tilt 
####################################
Data_Til <- Data_Til %>%
  filter(! BOLD_rTPJ=="NaN")
Data_Til
Data_Til$response[Data_Til$response=="0"] <- "Vertical"
Data_Til$response[Data_Til$response=="1"] <- "Tilted"

#get the mean activation at each ROI for each participants at each confidence level for each response
BOLD_til_subj <- aggregate(Data_Til[, 16:21], list(Data_Til$subj_id, Data_Til$confidence, Data_Til$response, Data_Til$task ), mean)
#rename the colum names 
BOLD_til_subj <- rename(BOLD_til_subj,c('subj_id'='Group.1', 'confidence'='Group.2', 'response'='Group.3', 'task'='Group.4'))
#get the group mean of activation for each ROI
BOLD_til_mean <- aggregate(BOLD_til_subj[, 5:10], list(BOLD_til_subj$confidence, BOLD_til_subj$response ), mean)
#get the se of activation for each ROI
BOLD_til_se <- aggregate(BOLD_til_subj[, 5:10], list(BOLD_til_subj$confidence, BOLD_til_subj$response ), se)
#combine with mean df==> ".x==mean, .y==se"
BOLD_til_mean <- inner_join(BOLD_til_mean, BOLD_til_se, by=c("Group.1", "Group.2"))
#rename the colum names 
BOLD_til_mean <- rename(BOLD_til_mean,c('confidence'='Group.1', 'response'='Group.2'))
```

```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3}
#################################### 
# Plotting rTPJ 
#################################### 
rTPJ_det <- ggplot(data=BOLD_det_mean, aes(x=confidence, y=BOLD_rTPJ.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_rTPJ.x-BOLD_rTPJ.y, ymax = BOLD_rTPJ.x+BOLD_rTPJ.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#e41a1c", "#377eb8")) +
  labs(title="rTPJ detection", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = element_blank(),
  legend.text = (element_text(size = 8)),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
rTPJ_det

rTPJ_dis <- ggplot(data=BOLD_dis_mean, aes(x=confidence, y=BOLD_rTPJ.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_rTPJ.x-BOLD_rTPJ.y, ymax = BOLD_rTPJ.x+BOLD_rTPJ.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#984ea3", "#4daf4a")) +
  labs(title="rTPJ discrimination", x= "confidence", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.85, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = element_blank(),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
rTPJ_dis

rTPJ_til <- ggplot(data=BOLD_til_mean, aes(x=confidence, y=BOLD_rTPJ.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_rTPJ.x-BOLD_rTPJ.y, ymax = BOLD_rTPJ.x+BOLD_rTPJ.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#999999","#f781bf")) +
  labs(title="rTPJ tilt recognition", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.7, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = element_blank(),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
rTPJ_til
```
&nbsp;

&nbsp;

```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3}
#################################### 
# Plotting vmPFC 
#################################### 
vmPFC_det <- ggplot(data=BOLD_det_mean, aes(x=confidence, y=BOLD_vmPFC.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_vmPFC.x-BOLD_vmPFC.y, ymax = BOLD_vmPFC.x+BOLD_vmPFC.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#e41a1c", "#377eb8")) +
  labs(title="vmPFC detection", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1.5, 0.5), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = element_blank(),
  legend.text = (element_text(size = 8)),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
vmPFC_det

vmPFC_dis <- ggplot(data=BOLD_dis_mean, aes(x=confidence, y=BOLD_vmPFC.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_vmPFC.x-BOLD_vmPFC.y, ymax = BOLD_vmPFC.x+BOLD_vmPFC.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#984ea3", "#4daf4a")) +
  labs(title="vmPFC detection", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1.5, 0.5), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = element_blank(),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
vmPFC_dis

vmPFC_til <- ggplot(data=BOLD_til_mean, aes(x=confidence, y=BOLD_vmPFC.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_vmPFC.x-BOLD_vmPFC.y, ymax = BOLD_vmPFC.x+BOLD_vmPFC.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#999999","#f781bf")) +
  labs(title="vmPFC detection", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1.5, 0.5), breaks=number_ticks(6))+
  theme(legend.position=c(0.7, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = element_blank(),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
vmPFC_til
```
&nbsp;

&nbsp;

```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3}
#################################### 
# Plotting pMFC
#################################### 
pMFC_det <- ggplot(data=BOLD_det_mean, aes(x=confidence, y=BOLD_pMFC.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_pMFC.x-BOLD_pMFC.y, ymax = BOLD_pMFC.x+BOLD_pMFC.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#e41a1c", "#377eb8")) +
  labs(title="pMFC detection ", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(0.2, 1.8), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
pMFC_det

pMFC_dis <- ggplot(data=BOLD_dis_mean, aes(x=confidence, y=BOLD_pMFC.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_pMFC.x-BOLD_pMFC.y, ymax = BOLD_pMFC.x+BOLD_pMFC.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#984ea3", "#4daf4a")) +
  labs(title="pMFC discrimination", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(0.2, 1.8), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
pMFC_dis

pMFC_til <- ggplot(data=BOLD_til_mean, aes(x=confidence, y=BOLD_pMFC.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_pMFC.x-BOLD_pMFC.y, ymax = BOLD_pMFC.x+BOLD_pMFC.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#999999","#f781bf")) +
  labs(title="pMFC tilt", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(0.2, 1.8), breaks=number_ticks(6))+
  theme(legend.position=c(0.7, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
pMFC_til
```
&nbsp;

&nbsp;

```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3}
#################################### 
# Plotting FPl
#################################### 
FPl_det <- ggplot(data=BOLD_det_mean, aes(x=confidence, y=BOLD_FPl.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_FPl.x-BOLD_FPl.y, ymax = BOLD_FPl.x+BOLD_FPl.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#e41a1c", "#377eb8")) +
  labs(title="FPl detection ", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-0.5, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
FPl_det

FPl_dis <- ggplot(data=BOLD_dis_mean, aes(x=confidence, y=BOLD_FPl.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_FPl.x-BOLD_FPl.y, ymax = BOLD_FPl.x+BOLD_FPl.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#984ea3", "#4daf4a")) +
  labs(title="FPl discrimination", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-0.5, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
FPl_dis

FPl_til <- ggplot(data=BOLD_til_mean, aes(x=confidence, y=BOLD_FPl.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_FPl.x-BOLD_FPl.y, ymax = BOLD_FPl.x+BOLD_FPl.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#999999","#f781bf")) +
  labs(title="FPl tilt", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-0.5, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.7, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
FPl_til
```
&nbsp;

<!-- MM: Are those nbsps necessary? -->

&nbsp;

```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3}
#################################### 
# Plotting FPm
#################################### 
FPm_det <- ggplot(data=BOLD_det_mean, aes(x=confidence, y=BOLD_FPm.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_FPm.x-BOLD_FPm.y, ymax = BOLD_FPm.x+BOLD_FPm.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#e41a1c", "#377eb8")) +
  labs(title="FPm detection ", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
FPm_det

FPm_dis <- ggplot(data=BOLD_dis_mean, aes(x=confidence, y=BOLD_FPm.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_FPm.x-BOLD_FPm.y, ymax = BOLD_FPm.x+BOLD_FPm.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#984ea3", "#4daf4a")) +
  labs(title="FPm discrimination", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.8, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
FPm_dis

FPm_til <- ggplot(data=BOLD_til_mean, aes(x=confidence, y=BOLD_FPm.x)) +
  geom_line(aes(colour = factor(response))) +
  geom_point(aes(color = factor(response)), size = 3) + 
  geom_errorbar( aes(ymin = BOLD_FPm.x-BOLD_FPm.y, ymax = BOLD_FPm.x+BOLD_FPm.y, colour = factor(response)), width = 0.1)+
  scale_color_manual(values=c("#999999","#f781bf")) +
  labs(title="FPm tilt", x= "confidence", y="mean activation", color="Response") +
  theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1, 1), breaks=number_ticks(6))+
  theme(legend.position=c(0.7, 0.15),  
                 legend.background = element_blank(),
                 legend.key = element_blank(),
        legend.title = (element_text(size = 8)),
  legend.text = (element_text(size = 8)),
  axis.title.y=element_blank(),
        plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
FPm_til
```

```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3}

BOLD_mean_subj <- rbind(BOLD_det_subj, BOLD_dis_subj, BOLD_til_subj)

#linear effect of conf (as continuous variables) on ROIs
lm_conf_vmPFC <- lm(formula = BOLD_vmPFC~confidence, data = BOLD_mean_subj)
lm_conf_pMFC <- lm(formula = BOLD_pMFC~confidence, data = BOLD_mean_subj)
lm_conf_rTPJ <- lm(formula = BOLD_rTPJ~confidence, data = BOLD_mean_subj)
lm_conf_FPl <- lm(formula = BOLD_FPl~confidence, data = BOLD_mean_subj)
lm_conf_FPm <- lm(formula = BOLD_FPm~confidence, data = BOLD_mean_subj)

#pull out beta and p values
b_lm_vmPFC <- coef(summary(lm_conf_vmPFC))[, "Estimate"]
b_lm_pMFC <- coef(summary(lm_conf_pMFC))[, "Estimate"]
b_lm_rTPJ <- coef(summary(lm_conf_rTPJ))[, "Estimate"]
b_lm_FPl <- coef(summary(lm_conf_FPl))[, "Estimate"]
b_lm_FPm <- coef(summary(lm_conf_FPm))[, "Estimate"]

p_lm_vmPFC <- coef(summary(lm_conf_vmPFC))[, "Pr(>|t|)"]
p_lm_pMFC <- coef(summary(lm_conf_pMFC))[, "Pr(>|t|)"]
p_lm_rTPJ <- coef(summary(lm_conf_rTPJ))[, "Pr(>|t|)"]
p_lm_FPl <- coef(summary(lm_conf_FPl))[, "Pr(>|t|)"]
p_lm_FPm <- coef(summary(lm_conf_FPm))[, "Pr(>|t|)"]

as.numeric(b_lm_vmPFC)
as.numeric(b_lm_pMFC)
as.numeric(b_lm_rTPJ)
as.numeric(b_lm_FPl)
as.numeric(b_lm_FPm)
as.numeric(p_lm_vmPFC)
as.numeric(p_lm_pMFC)
as.numeric(p_lm_rTPJ)
as.numeric(p_lm_FPl)
as.numeric(p_lm_FPm)

#lm with interactor task
lm_task_vmPFC <- lm(formula = BOLD_vmPFC~confidence+ confidence:task, data = BOLD_mean_subj)
lm_task_rTPJ <- lm(formula = BOLD_rTPJ~confidence+ confidence:task, data = BOLD_mean_subj)
lm_task_mPFC <- lm(formula = BOLD_pMFC~confidence+ confidence:task, data = BOLD_mean_subj)
lm_task_FPl <- lm(formula = BOLD_FPl~confidence+ confidence:task, data = BOLD_mean_subj)
lm_task_FPm <- lm(formula = BOLD_FPm~confidence+ confidence:task, data = BOLD_mean_subj)

#lm with interactor response detection
lm_resp_vmPFC <- lm(formula = BOLD_vmPFC~confidence+ confidence:response, data = BOLD_det_subj)
lm_resp_rTPJ <- lm(formula = BOLD_rTPJ~confidence+ confidence:response, data = BOLD_det_subj)
lm_resp_mPFC <- lm(formula = BOLD_pMFC~confidence+ confidence:response, data = BOLD_det_subj)
lm_resp_FPl <- lm(formula = BOLD_FPl~confidence+ confidence:response, data = BOLD_det_subj)
lm_resp_FPm <- lm(formula = BOLD_FPm~confidence+ confidence:response, data = BOLD_det_subj)

#lm with interactor response discrimination
lm_resp_vmPFC <- lm(formula = BOLD_vmPFC~confidence+ confidence:response, data = BOLD_dis_subj)
lm_resp_rTPJ <- lm(formula = BOLD_rTPJ~confidence+ confidence:response, data = BOLD_dis_subj)
lm_resp_mPFC <- lm(formula = BOLD_pMFC~confidence+ confidence:response, data = BOLD_dis_subj)
lm_resp_FPl <- lm(formula = BOLD_FPl~confidence+ confidence:response, data = BOLD_dis_subj)
lm_resp_FPm <- lm(formula = BOLD_FPm~confidence+ confidence:response, data = BOLD_dis_subj)

#lm with interactor response tilt
lm_resp_vmPFC <- lm(formula = BOLD_vmPFC~confidence+ confidence:response, data = BOLD_til_subj)
lm_resp_rTPJ <- lm(formula = BOLD_rTPJ~confidence+ confidence:response, data = BOLD_til_subj)
lm_resp_mPFC <- lm(formula = BOLD_pMFC~confidence+ confidence:response, data = BOLD_til_subj)
lm_resp_FPl <- lm(formula = BOLD_FPl~confidence+ confidence:response, data = BOLD_til_subj)
lm_resp_FPm <- lm(formula = BOLD_FPm~confidence+ confidence:response, data = BOLD_til_subj)

```
## Effect of confidence on BOLD signal in ROIs
From our data, negative linear confidence-related effects were observed in right Temporoparietal Junction (rTPJ) ($\beta$=`r apa(b_lm_rTPJ[2],2,T)`, p=`r apa(p_lm_rTPJ[2],3,T)`), Posterior Medial Frontal Cortex (pMFC)($\beta$=`r apa(b_lm_pMFC[2], 2,T)`, p=`r myround_p(apa(p_lm_pMFC[2], 3,T))`), as well as polsitive linear correlation between confidence and BOLD signals in Ventromedial Prefrontal Cortex (vmPFC)($\beta$=`r apa(b_lm_vmPFC[2],2,T)`, p=`r myround_p(apa(p_lm_vmPFC[2],3,T))`), Medial Frontopolar Cortex (FPm)($\beta$=`r apa(b_lm_FPm[2],2,T)`, p=`r apa(p_lm_FPm[2], 3,T)`). 

To investigate whether linear effects of confidence on BOLD signal were influenced by the type of task (Detection vs. Discrimination vs. Tilt recognition) and/or reponse (Yes vs. NO; Clockwise vs. Anticlockwise; Vertical vs. Tilted), linear models with interactions were tested. The effects of confidence failed to show a significant difference between three tasks in all ROIs (all p values > 0.23). No sognificant effect was observed between Yes and No response in detection (all p values > 0.11), between Clockwise and Anticlockwise responses in discrimination (all p values > 0.33) or between Vertical and Tilted responses in tilt recognition (all p values > 0.14).

```{r echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3}
#non-linear effect of conf and response (as categorical variables) on rTPJ
aov.resp_rTPJ_det <- aov(BOLD_rTPJ~response,data=BOLD_det_subj)
aov.conf_rTPJ_det <- aov(BOLD_rTPJ~confidence,data=BOLD_det_subj)

aov.resp_rTPJ_dis <- aov(BOLD_rTPJ~response,data=BOLD_dis_subj)
aov.conf_rTPJ_dis <- aov(BOLD_rTPJ~confidence,data=BOLD_dis_subj)

aov.resp_rTPJ_til <- aov(BOLD_rTPJ~response,data=BOLD_til_subj)
aov.conf_rTPJ_til <- aov(BOLD_rTPJ~confidence,data=BOLD_til_subj)

summary(aov.resp_rTPJ_det)
summary(aov.conf_rTPJ_det)
summary(aov.resp_rTPJ_dis)
summary(aov.conf_rTPJ_dis)
summary(aov.resp_rTPJ_til)
summary(aov.conf_rTPJ_til)

#effect of conf and response on vmPFC
```
&nbsp;


```{r  mixed_effects, echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.width=2.5, fig.height=3 , cache=TRUE}
color_scheme <- tibble(Detection=c("#e41a1c", "#377eb8"), 
                       Discrimination=c("#984ea3", "#4daf4a"),
                       Tilt=c("#999999","#f781bf"))

plot_re_coefficients <- function(cur_task, ROI, df) {
  
  df$conf_as_factor <- factor(df$confidence)

  # fit mixed effects model:
  coefs <- lmer(
    paste('BOLD_',ROI,' ~ conf_as_factor*response + (1|subj_id)',sep=''), #note that this is a random intercept only model!
    df%>%filter(task==cur_task)) %>%
    tidy()
  
  # add confidence and response rows
  coefs$confidence =  c(1:6,1:6, NA, NA) # the last two rows are for random effects
  coefs$response = c(rep(0,6), rep(1,6), NA, NA)
  
  # plot
  plot <-ggplot(data=coefs, aes(x=confidence, y=estimate)) +
    geom_line(aes(colour = factor(response))) +
    geom_point(aes(color = factor(response)), size = 3) + 
    geom_errorbar( aes(ymin = estimate+std.error, ymax =estimate-std.error, colour = factor(response)), width = 0.1)+
    scale_color_manual(values=color_scheme[[cur_task]]) +
    labs(title=paste(ROI,cur_task), x= "confidence", color="Response") +
    theme_classic() + scale_x_continuous(limits = c(0.5, 6),breaks=number_ticks(6)) + scale_y_continuous(limits = c(-1.5, 1.5), breaks=number_ticks(6))+
    theme(legend.position=c(0.7, 0.15),  
                   legend.background = element_blank(),
                   legend.key = element_blank(),
          legend.title = (element_text(size = 8)),
    legend.text = (element_text(size = 8)),
          plot.title = (element_text(color = "black", size = 12, face = "italic"))) 
  print(plot)
  
}

for (ROI in list('rTPJ','vmPFC','pMFC','FPl','FPm')) {
  for (task in list('Detection','Discrimination','Tilt')) {
    print(ROI)
    plot_re_coefficients(task,ROI,Data_Valid)
  }
}
```

## Citation 
[@denison2018pnasusa][@mazor2020e] 
&nbsp;

## Reference 
